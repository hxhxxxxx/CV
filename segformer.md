**摘要部分**
segformer是一个语义分割框架，将transformer与轻量的MLP结合
该模型有以下两个特点
（1）可以输出多尺度特征，而且不需要位置编码
（2）使用MLP来聚合不同层的信息，不用原先复杂的解码器，并且结合了注意力机制

语义分割：与图像分类有关，生成了每个像素类别的预测，而不是图像类别的预测
在开创性工作中，引入FCN，完全卷积网络来对语义分割任务进行处理

多尺度特征与单尺度特征：
这里的尺度指的是对图像进行分割时的大小
因为图像中物体的大小不一样，所以如果只是用一个尺度分割得到的结果可能会不尽如人意，所以引入多尺度分割
不同尺度的特征形成了金字塔结构，在很多文章中都有所体现
此外，还可以通过特征融合的方式进行多尺度信息的整合。常用的方法包括级联式的特征融合、注意力机制的特征融合等。这些方法能够有效地综合不同尺度下的特征，提高分割算法的性能。

在之前ViT模型中，都是单尺度低分辨率特征，所以具有一定的局限性，后续有关工作提出了PVT，它是ViT加入金字塔结构的拓展，使得它有多尺度输出特征

而本篇文章的新颖之处在于
·舍弃了位置编码，以及使用了分层的transformer编码器，以达到多尺度的作用
·轻量级的全MLP解码器的设计，舍弃了原先复杂的模型
·在语义分割数据集上表现良好

具体来说，
由于避免使用位置编码，使得能够利用多尺度特征分割，不至于说在训练集上训练好的位置编码，由于测试集上的分辨率不一样导致有所影响
这样编码器就可以生成高分辨率的精细特征与低分辨率的粗略特征，跟vit相比有了明显的进步
其次对于MLP解码器，它利用了transformer模块生成的特征，将较低层的注意力去保持局部性，最高层的注意力去注意非局部的特征，这样就结合局部与全局的信息

**相关工作**
对于H*W*3的图像，分别将其分成1/4，1/8，1/16，1/32patches，作为输入以此来得到多级特征
然后再将多级特征传递给全MLP解码器对掩码进行预测

层次特征表示：用不同的大小的patches得到不同特征输出
重叠部分合并：把不同分辨率的特征的重叠部分进行融合，以此来保留局部性的特征
高效的注意力计算：通过reshape减少需要处理的pacthes的数量
混合FFN：避免使用位置编码




**#TMO模型#**

**Introduction 部分**

主要讨论如何利用光流信息与图像中的物体特征
受显著物体与背景相比通常具有独特运动这一观察结果的启发，最近的无监督VOS方法利用了从光流图获得的运动提示以及从RGB图像获得的出现提示。
在特征嵌入过程中，外观和运动线索被融合，以提供相互指导
但是传统的一些方法，会对于光流运动信息不明显的情况，处理效果并不好，所以TMO试图解决这一问题

跟传统方法不同
TMO在编码的过程中，分别会对RGB图与光流图分别进行特征提取，并且在提取的过程中并不互相影响，而且在解码器融合的时候也只是简单的相加
此外，光流运动信息也可以不被选中作为参考，如果不选中的话另一个也是对RGB图的特征，我们还提出了一种协作网络学习策略。由于在所提出的网络中可选地采用了运动线索，
因此需要在训练阶段提供具有和不具有光流图的训练样本，以满足我们的网络设计目标。获得这些训练样本的直接方法是有意且随机地丢弃VOS训练样本中的光流图。

TMO的优势：
·提出了协作网络学习策略，把运动流作为一个可选的选项
·可以处理低光流图，甚至可以不需要光流图
·性能很好
·编码器结构简单，并且推理速度快，实时处理速度快

**相关工作部分**
temporal coherence
就是在说一个视频的不同帧之间有着许多高度相关的内容，可以在处理的过程中运用到相关信息
motion information
因为显著的物体一般都会在视频中有运动的信息，所以可以利用这个信息
但是有些运动信息中噪声太多了会对物体分割产生干扰，
所以提出了一种方法让帧内对比度，光流等特征相互辅助推断，但是这种方法也同样存在问题，会对光流的要求度较高，所以难以处理一些低光流的情景
network learning strategy
就是用了一些其他的类似于静态数据的东西来进行预训练之类

**方法部分**
目标：分割出目标物体的掩码
输入：RGB图
RGB图提供外观特征，以及利用一个经过预训练的提取光流的模型得到每一帧的光流信息提供一些运动信息
把上面所说的两种信息融合一下然后去推断出当前帧需要分割的目标物体的掩码

TMO模型的架构
分别从RGB图像和RGB图像或光流图中分别提取外观和运动特征。如果打开运动流，则会同时利用外观和运动提示；如果关闭运动流，仅利用外观提示。解码器对出现和运动嵌入后的融合特征进行逐步解码，以预测最终的二进制分割掩码

每个解码块包括一个融合不同特征的卷积层、一个增强通道和空间特征表示的CBAM层[32]，以及增加特征空间大小的上采样层。

对于光流图的提取，这里运用了RAFT模型来提取，对于当前帧光流图来提取是以当前帧与后一帧作为输入，而对于最后一帧，则是利用当前帧与前一帧
并且光流图的提取在推断之前就提前生成了，这样可以减轻训练时间

对于编码器，使用Resnet-101网络，一共有四层，每层的大小都为前一层的一半，为了更好地提取特征，该网络在Imagenet中经过了预训练






首先在run.py 文件中定义了四个阶段
分别是 
set device     启动设备

define model   定义模型
model=TMO().eval()

training stage 训练阶段，调整模型的参数
testing stage  测试阶段，对不同的数据集使用调好的模型来测试结果

主要来看一下TMO.py中的内容

先跳过前面的部分，直接来到TMO类跟VOS类
可以看到在TMO类的初始化部分有用到VOS类，那就先简单看一下VOS类，它主要分为三个部分，分别是对外观编码器进行encoder，对motion进行encoder，最后是进行decoder操作
然后具体看一下TMO类中是如何进行操作的

首先先看一下TMO类的输入，分别是图像与光流，然后生成每一帧的分割结果
首先先是对图像的信息进行提取，分别提取batch size单次前向传播的样本数量,sequence length输入序列的帧数,以及单个图像的长宽
然后重新调整一下图像的形状，把imgs的形状从【B*L,-1,H1,W1】调整成 【B,L,-1,s,s】,为方便后续处理

接着是对每一帧信息进行处理：
先是创建了两个列表，一个是score_lst用来记录每个帧的soft scores，即概率分布，一个是mask_lst,记录了每个帧的通过对最终分数进行argmax操作得到的二值掩码
然后就是具体的操作，首先先是对每一帧的掩码预测部分
这里是提取两个特征，分别是外观特征与运动特征，分别以第i帧图像与第i帧光流信息作为输入来提取
然后再用这两个特征作为输入来 通过解码器来得到一个最终的得分，如果原来的图像并不为设定的长宽，那么把最终得分进行大小变化还原成原先的大小
如果单次传播的样本大小不为1，那么把这个最终得分放入score_lst中去
如果为1，那么需要经过一定的处理，首先把得分进行softmax操作，然后找到其中的最大值，把其所属的类别赋予mask变量，最后把mask变量放入mask_lst列表中
最后输出即可

然后来看encoder与decoder部分
整个编码模块使用了预训练的Resnet-101作为骨干网络的
encoder部分的前向传播中，输入的图像数据减去均值并除以标准差进行标准化，然后通过一系列的卷积层，批量归一化层，激活函数层，最大池化层，然后得到不同抽象级别的特征表示
卷积层可以提取图像的低级特征；批量归一化层会对卷积层输出进行归一化处理以减少内部协变量的移动，加快训练速度，同时有一定的正则化效果
relu层对输出进行非线性变换，使得模型可以学习和表示更复杂的模式；maxpool层可以对输入进行下采样，减少模型计算复杂度，同时保留重要特征信息
self.layer 层都是Resnet-101模型的主要部分，每层都包含多个残差块，每个残差块都包含几个卷积层和非线性激活函数，这些层可以学习和表示图像的高级特征

对于解码模块
这个模块用于从编码模块提取的特征中恢复出原始图像，它通过一系列的卷积，relu激活，注意力模块和上采样操作，逐步将深层的低分辨率特征图恢复到高分辨率的输出
它的操作是先将两类特征的s32键值进行相加，然后通过conv1卷积层跟blend1混合层，再通过cbam1模块进行注意力机制处理。
之后再将处理后的结果进行上采样，即增大图像尺寸，放大因子为2
将上采样后的结果与两种类型的特征s16键所对应的值经过conv2卷积层处理后的结果进行拼接，然后通过blend2混合层和cbam2注意力机制处理，之后也是类似的处理方式
最后将结果先通过predictor就是一个卷积层，然后再进行上采样放大因子为4，得到最终的分数
上面说的conv层是基础模块中的convRelu层，blend层也是convRelu层，二者的卷积核大小有所不同

对于最开始的基础模块，其中包含Conv,ConvRelu和CBAM。前两个是卷积层和带Relu激活函数的卷积层，用于特征提取。最后一个是注意力模块，用于增强网络对重要特征的关注
这里主要注意一下CBAM模块
1.  首先 对输入x通过conv1,即conv卷积操作
2.  然后 对x进行全局平均池化和全局最大池化，然后通过conv2层，即先进行convRelu,再接着conv层操作，然后将二者相加并通过sigmoid函数，该函数将卷积层的输出转换为权重
用于调整特征图的通道和空间信息
3. 接着， x与c进行元素级别的乘法操作，得到通道注意力调整后的x
4. 然后 计算通道平均平均值和最大值，将两者沿通道维度进行拼接，然后通过conv3层冰通过sigmoid函数得到空间注意力s
5. 最后 x与s进行元素级别的乘法操作，得到经过空间注意力调整后的x
这个模块的目的是通过引入通道注意力和空间注意力，使得模型能够更好地关注输入特征中的重要部分
至于通道注意力与空间注意力是如何得到的
先讲通道注意力，全局平均池化与最大池化对每个通道进行全局的统计，然后通过卷积层学习全局统计信息到通道权重的映射，然后再通过sigmoid函数得到该通道的权重，这个值可以理解为每个通道的重要性
这样就得到通道注意力
而空间注意力也是同样的道理，CBAM模块通过结合两种注意力机制，使得模型能够同时关注重要的通道与空间位置

明日任务：了解一下resnet网络，然后制作一下PPT




















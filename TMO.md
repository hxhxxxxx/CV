**#TMO模型#**

**Introduction 部分**

主要讨论如何利用光流信息与图像中的物体特征
受显著物体与背景相比通常具有独特运动这一观察结果的启发，最近的无监督VOS方法利用了从光流图获得的运动提示以及从RGB图像获得的出现提示。
在特征嵌入过程中，外观和运动线索被融合，以提供相互指导
但是传统的一些方法，会对于光流运动信息不明显的情况，处理效果并不好，所以TMO试图解决这一问题

跟传统方法不同
TMO在编码的过程中，分别会对RGB图与光流图分别进行特征提取，并且在提取的过程中并不互相影响，而且在解码器融合的时候也只是简单的相加
此外，光流运动信息也可以不被选中作为参考，如果不选中的话另一个也是对RGB图的特征，我们还提出了一种协作网络学习策略。由于在所提出的网络中可选地采用了运动线索，
因此需要在训练阶段提供具有和不具有光流图的训练样本，以满足我们的网络设计目标。获得这些训练样本的直接方法是有意且随机地丢弃VOS训练样本中的光流图。

TMO的优势：
·提出了协作网络学习策略，把运动流作为一个可选的选项
·可以处理低光流图，甚至可以不需要光流图
·性能很好
·编码器结构简单，并且推理速度快，实时处理速度快

**相关工作部分**
temporal coherence
就是在说一个视频的不同帧之间有着许多高度相关的内容，可以在处理的过程中运用到相关信息
motion information
因为显著的物体一般都会在视频中有运动的信息，所以可以利用这个信息
但是有些运动信息中噪声太多了会对物体分割产生干扰，
所以提出了一种方法让帧内对比度，光流等特征相互辅助推断，但是这种方法也同样存在问题，会对光流的要求度较高，所以难以处理一些低光流的情景
network learning strategy
就是用了一些其他的类似于静态数据的东西来进行预训练之类

**方法部分**





